# Pr√°ctica 1: Paralelizaci√≥n con OpenMP

## Computaci√≥n Paralela (CPA) - Curso 2024/25

---

## üìã Descripci√≥n General

Esta pr√°ctica consta de **3 sesiones** enfocadas en el aprendizaje de paralelizaci√≥n con OpenMP a trav√©s de diferentes problemas computacionales. Cada sesi√≥n trabaja con conceptos progresivamente m√°s avanzados de programaci√≥n paralela.

---

## üóÇÔ∏è Estructura de la Pr√°ctica

### **Sesi√≥n 1: Integraci√≥n Num√©rica**
- **Archivos:** `integral.c`
- **Objetivo:** Aprender a compilar programas OpenMP y paralelizar bucles sencillos
- **Concepto:** C√°lculo num√©rico de integrales usando el m√©todo de los rect√°ngulos

### **Sesi√≥n 2: Procesamiento de Im√°genes**
- **Archivos:** `imagenes.c`, `peppers.ppm`, `peppers-1k.ppm`
- **Objetivo:** Implementar filtrado de im√°genes en paralelo
- **Concepto:** Aplicar filtros de media ponderada con OpenMP

### **Sesi√≥n 3: N√∫meros Primos**
- **Archivos:** `primo_grande.c`, `primo_numeros.c`
- **Objetivo:** Implementar algoritmos paralelos con reparto expl√≠cito de trabajo
- **Concepto:** B√∫squeda y conteo de n√∫meros primos

---

## üöÄ Configuraci√≥n Inicial

### Requisitos
- Sistema operativo Linux
- Compilador GCC con soporte OpenMP
- Acceso al cluster **kahan** (para ejecuciones con m√∫ltiples cores)
- Escritorio remoto DSIC-LINUX: https://polilabsvpn.upv.es/

### Crear estructura de carpetas
```bash
# Crear carpeta para el c√≥digo fuente
mkdir -p W/cpa/prac1
cd W/cpa/prac1
```

---

## üìù Sesi√≥n 1: Integraci√≥n Num√©rica

### Compilaci√≥n b√°sica
```bash
gcc -Wall -o integral integral.c -lm
```

### Compilaci√≥n con OpenMP
```bash
gcc -fopenmp -Wall -o pintegral pintegral.c -lm
```

### Ejecuci√≥n local
```bash
# Con 4 hilos, usando la variante 1
OMP_NUM_THREADS=4 ./pintegral 1

# Con 500000 rect√°ngulos
OMP_NUM_THREADS=4 ./pintegral 1 500000
```

### Ejecuci√≥n en el cluster kahan

#### 1. Conectarse al cluster
```bash
ssh -Y -l login@alumno.upv.es kahan.dsic.upv.es
```

#### 2. Preparar directorio de trabajo
```bash
mkdir prac1
cd prac1
gcc -Wall -fopenmp -o pintegral ~/W/cpa/prac1/pintegral.c -lm
```

#### 3. Crear fichero de trabajo (jobopenmp.sh)
```bash
#!/bin/bash
#SBATCH --nodes=1
#SBATCH --time=5:00
#SBATCH --partition=cpa

OMP_NUM_THREADS=16 ./pintegral 1
```

#### 4. Lanzar trabajo
```bash
sbatch ~/W/cpa/prac1/jobopenmp.sh
```

#### 5. Ver resultados
```bash
cat slurm-620.out  # Donde 620 es el n√∫mero de trabajo
```

### Conceptos clave
- Directivas `#pragma omp parallel for`
- Cl√°usulas `private` y `reduction`
- Funci√≥n `omp_get_wtime()` para medir tiempos
- Funci√≥n `omp_get_max_threads()` para obtener n√∫mero de hilos

---

## üñºÔ∏è Sesi√≥n 2: Procesamiento de Im√°genes

### Compilaci√≥n
```bash
gcc -fopenmp -Wall -o imagenes imagenes.c -lm
```

### Copiar archivos al cluster
```bash
cp ~/W/cpa/prac1/*.ppm ~/prac1/
```

### Verificar resultados
```bash
# Comparar salida con referencia
cmp peppers-fil.ppm ref.ppm
```

### Estrategia de paralelizaci√≥n
Analizar los 5 bucles anidados:
1. **Bucle de pasos** (externo)
2. **Bucle de filas**
3. **Bucle de columnas**
4. **Bucle de radio por filas**
5. **Bucle de radio por columnas**

Para cada bucle:
- ‚úÖ Analizar dependencias entre iteraciones
- ‚úÖ Determinar variables compartidas/privadas
- ‚úÖ Implementar paralelizaci√≥n
- ‚úÖ Verificar correctitud del resultado
- ‚úÖ Medir tiempos de ejecuci√≥n

### Recomendaciones
- Empezar con el bucle m√°s interno
- Usar inicialmente 2 hilos para pruebas
- Evitar saturar la cola del cluster
- No usar `reduction` sobre miembros de struct

---

## üî¢ Sesi√≥n 3: N√∫meros Primos

### Parte 1: Buscar el primo m√°s grande

#### Compilaci√≥n
```bash
gcc -fopenmp -Wall -o primo_grande primo_grande.c -lm
```

#### Paralelizaci√≥n manual
Reparto c√≠clico de iteraciones entre hilos:
```c
#pragma omp parallel ...
{
    int id = omp_get_thread_num();
    int nhilos = omp_get_num_threads();
    
    for (i = 3 + 2*id; p && i <= s; i += 2*nhilos)
        if (n % i == 0) p = 0;
}
```

**Nota importante:** Usar `volatile int p;` para evitar problemas de optimizaci√≥n del compilador.

### Parte 2: Contar primos hasta un n√∫mero grande

#### Estrategias de paralelizaci√≥n
1. **Opci√≥n A:** Paralelizar el bucle principal con funci√≥n `primo()` secuencial
2. **Opci√≥n B:** Usar funci√≥n `primo()` paralela (menos eficiente)

#### Planificaciones a probar
```bash
# Est√°tica sin chunk
schedule(static)

# Est√°tica con chunk 1
schedule(static, 1)

# Din√°mica
schedule(dynamic)

# Usando variable de entorno
OMP_SCHEDULE="static,6" ./primo_numeros
```

---

## üìä Toma de Tiempos

### Plantilla de resultados
```
Tiempo secuencial: _____________

Tiempo de versiones paralelas:
                Version 1    Version 2    ...
2 hilos         _________    _________    ...
8 hilos         _________    _________    ...
32 hilos        _________    _________    ...
```

### Medir tiempos en el c√≥digo
```c
#include <omp.h>

double t1, t2;
t1 = omp_get_wtime();
// ... c√≥digo a medir ...
t2 = omp_get_wtime();
printf("Tiempo: %f\n", t2-t1);
```

---

## üõ†Ô∏è Comandos √ötiles del Cluster

```bash
# Ver estado de la cola
squeue

# Cancelar un trabajo
scancel 620

# Ver contenido de archivo
cat slurm-620.out

# Copiar archivos a W
cp slurm-620.out ~/W/cpa/prac1
```

---

## üìå Opciones de Compilaci√≥n

| Opci√≥n | Descripci√≥n |
|--------|-------------|
| `-fopenmp` | Habilitar soporte OpenMP |
| `-Wall` | Mostrar todas las advertencias |
| `-o archivo` | Especificar nombre del ejecutable |
| `-lm` | Enlazar librer√≠a matem√°tica |

---

## ‚ö†Ô∏è Notas Importantes

- **No ejecutar programas largos en el front-end** del cluster, solo para compilar y lanzar trabajos
- Los ejecutables **no deben estar en la carpeta W**, usar `~/prac1`
- El cluster kahan tiene **4 nodos con 64 cores cada uno**
- Usar `#SBATCH --nodes=1` para programas OpenMP (memoria compartida)
- Los resultados de trabajos se guardan en archivos `slurm-JOBID.out`

---

## üéØ Objetivos de Aprendizaje

- ‚úÖ Compilar y ejecutar programas OpenMP
- ‚úÖ Paralelizar bucles con `parallel for`
- ‚úÖ Usar cl√°usulas `private`, `shared`, `reduction`
- ‚úÖ Realizar reparto expl√≠cito de trabajo entre hilos
- ‚úÖ Medir y analizar tiempos de ejecuci√≥n
- ‚úÖ Trabajar con el sistema de colas SLURM
- ‚úÖ Comprender diferentes estrategias de planificaci√≥n

---

## üìö Recursos Adicionales

- Documentaci√≥n cluster kahan: Material de la asignatura
- Formato PPM: Visualizar con `irfanview` o `display`
- Benchmarks de im√°genes: https://links.uwaterloo.ca/Repository.html

---

## üë• Soporte

Para dudas sobre el producto Claude o la API de Anthropic, consultar:
- Soporte general: https://support.claude.com
- Documentaci√≥n API: https://docs.claude.com
